{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR calculation with gaussian and KDE pdf and CLLR validation using 10-fold cross validation\n",
    "\n",
    "Scores calculated using OpenFace (docker image bamos/openface) on a modified version of the LFW dataset. The known errors of the dataset were corrected and only persons with more than one picture were included. For the remaining images, OpenFace failed to detect a face and were excluded from the analisys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kdepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:24:24.125086Z",
     "start_time": "2020-10-05T13:24:20.314604Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew, norm\n",
    "from KDEpy import FFTKDE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:25:13.626377Z",
     "start_time": "2020-10-05T13:24:32.750870Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('scores_lfw2_sim.csv', sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:26:06.941877Z",
     "start_time": "2020-10-05T13:26:06.858575Z"
    }
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:26:14.647804Z",
     "start_time": "2020-10-05T13:26:14.636635Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = scores.index.to_numpy()\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar scores ss e ds, sem perder a referÃªncia dos nomes e descartando as duplicidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:58:16.018403Z",
     "start_time": "2020-10-05T13:47:17.005656Z"
    }
   },
   "outputs": [],
   "source": [
    "def same(a,b):\n",
    "    a=os.path.splitext(a)[0]\n",
    "    a_name = a[:-5]\n",
    "    b=os.path.splitext(b)[0]\n",
    "    b_name = b[:-5]\n",
    "    if a_name == b_name:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "ss=[]\n",
    "ds=[]\n",
    "s_names=[]\n",
    "d_names=[]\n",
    "# for loops to check only upper half of the scores matrix, without diagonal -> won't get any scores of identical files.\n",
    "# Check if files are from same person or from different persons, according to filename prefix.\n",
    "for i in range(0,len(filenames)):\n",
    "    for j in range(i+1,len(filenames)):\n",
    "        f1 = filenames[i]\n",
    "        f2 = filenames[j]\n",
    "        if same(f1,f2):\n",
    "            ss.append(scores[f2][f1])\n",
    "            s_names.append([f2,f1])\n",
    "        else:\n",
    "            ds.append(scores[f2][f1])\n",
    "            d_names.append([f2,f1])\n",
    "print(s_names[0],ss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T13:59:50.084500Z",
     "start_time": "2020-10-05T13:59:47.721776Z"
    }
   },
   "outputs": [],
   "source": [
    "n_ds = len(ds)\n",
    "n_ss = len(ss)\n",
    "min_score = min(min(ds),min(ss))\n",
    "max_score = max(max(ds),max(ss))\n",
    "print (n_ss,\"genuine scores loaded.\")\n",
    "print (n_ds,\"impostor scores loaded.\")\n",
    "print (\"Minimum score:\",min_score)\n",
    "print (\"Maximum score:\",max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit normal distributions to SS and DS scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T14:01:30.057174Z",
     "start_time": "2020-10-05T14:01:24.175599Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-1, 1.0000001, 0.005)\n",
    "ss_hist, _ = np.histogram(ss, bins=bins, density=True)\n",
    "ds_hist, _ = np.histogram(ds, bins=bins, density=True)\n",
    "len(ss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T14:03:15.081286Z",
     "start_time": "2020-10-05T14:03:11.200595Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 400)\n",
    "ss_mean,ss_std = norm.fit(ss)\n",
    "ds_mean,ds_std = norm.fit(ds)\n",
    "ss_norm = norm.pdf(x, ss_mean,ss_std)\n",
    "ds_norm = norm.pdf(x, ds_mean,ds_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate pdf's using KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T14:07:05.036695Z",
     "start_time": "2020-10-05T14:07:00.834806Z"
    }
   },
   "outputs": [],
   "source": [
    "#x = np.linspace(-1, 1, 200)\n",
    "d_weights = np.arange(len(ds)) + 1\n",
    "s_weights = np.arange(len(ss)) + 1\n",
    "estimator = FFTKDE(kernel='biweight', bw='silverman')\n",
    "#estimator = FFTKDE(kernel='gaussian', bw='ISJ')\n",
    "#estimator = FFTKDE(kernel='gaussian', bw=0.3)\n",
    "ss_kde = estimator.fit(ss, weights=s_weights).evaluate(x)\n",
    "ds_kde = estimator.fit(ds, weights=d_weights).evaluate(x)\n",
    "ss_kde = estimator.fit(ss).evaluate(x)\n",
    "ds_kde = estimator.fit(ds).evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T14:11:51.246772Z",
     "start_time": "2020-10-05T14:11:51.136269Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x, ss_kde, label='SS - KDE', color='blue')\n",
    "ax1.plot(x, ds_kde, label='DS - KDE', color='red')\n",
    "#ax1.hist(ss, bins=int(len(x)/2), alpha=0.3, label=\"SS Histogram\", density=True, color='blue')\n",
    "#ax1.hist(ds, bins=int(len(x)/2), alpha=0.3, label=\"DS Histogram\", density=True, color='red')\n",
    "ax1.plot(x,ss_norm, label=\"SS - Gaussian fit\", color=\"green\")\n",
    "ax1.plot(x,ds_norm, label=\"DS - Gaussian fit\", color=\"yellow\")\n",
    "ax1.plot(x,ss_hist, label=\"SS hist\", color=\"gray\", linestyle=\"dashed\")\n",
    "ax1.plot(x,ds_hist, label=\"DS hist\", color=\"black\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Escore\")\n",
    "plt.ylabel(\"Freq. relativa / Dens. probabilidade\")\n",
    "ax1.grid(True, ls='--'); ax1.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for calculating LR and CLLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_idx(array, score):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - score)).argmin()\n",
    "    return idx\n",
    "\n",
    "#def lr(score):\n",
    "#    idx = find_nearest_idx(x, score)\n",
    "#    return ss_norm[idx]/ds_norm[idx]\n",
    "def lr(score, method):\n",
    "    idx = find_nearest_idx(x, score)\n",
    "    if method == \"kde\":\n",
    "        return ss_kde[idx]/ds_kde[idx]\n",
    "    elif method == \"gauss\":\n",
    "        return ss_norm[idx]/ds_norm[idx]\n",
    "    else:\n",
    "        print(\"Choose one of the two methods: kde or gauss.\")\n",
    "        return None\n",
    "\n",
    "def get_cllr(lr_ss, lr_ds):\n",
    "    n_ss = len(lr_ss) \n",
    "    n_ds = len(lr_ds)\n",
    "    cllr_ss = 0\n",
    "    cllr_ds = 0\n",
    "    for a in lr_ss:\n",
    "        cllr_ss += math.log2(1+1/a)\n",
    "    for b in lr_ds:\n",
    "        cllr_ds += math.log2(1+b)\n",
    "    cllr = 0.5*(cllr_ss/n_ss + cllr_ds/n_ds)\n",
    "    return cllr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just for debugging\n",
    "#print(lr(0.6, \"gauss\"), ss_kde[find_nearest_idx(x,0.6)]/ds_kde[find_nearest_idx(x,0.6)], lr(0.6,\"kde\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 10 folds for each group (SS and DS), fit gaussian pdf to train set and compute CLLR for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_ss and p_ds = partition sizes for ss and ds sets\n",
    "p_ss = int(n_ss/10)\n",
    "p_ds = int(n_ds/10)\n",
    "ss_test=[]\n",
    "ds_test=[]\n",
    "cllr_norm = []\n",
    "cllr_kde = []\n",
    "for i in range(0,10):\n",
    "    ss_test = ss[int(i*p_ss):int((1+i)*p_ss)]\n",
    "    ds_test = ds[int(i*p_ds):int((1+i)*p_ds)]\n",
    "    ss_train_a = ss[:int(i*p_ss)]\n",
    "    ss_train_b = ss[int((1+i)*p_ss):]\n",
    "    ss_train = np.concatenate((ss_train_a, ss_train_b))\n",
    "    ds_train_a = ds[:int(i*p_ds)]\n",
    "    ds_train_b = ds[int((1+i)*p_ds):]\n",
    "    ds_train = np.concatenate((ds_train_a, ds_train_b))\n",
    "    \n",
    "    #generate gaussians PDF from train data\n",
    "    ss_mean,ss_std = norm.fit(ss_train)\n",
    "    ds_mean,ds_std = norm.fit(ds_train)\n",
    "    ss_norm = norm.pdf(x, ss_mean,ss_std)\n",
    "    ds_norm = norm.pdf(x, ds_mean,ds_std)\n",
    "    \n",
    "    #estimate pdf's from train data using KDE\n",
    " \n",
    "    estimator = FFTKDE(kernel='biweight', bw='silverman')\n",
    "    #estimator = FFTKDE(kernel='gaussian', bw='ISJ')\n",
    "    #estimator = FFTKDE(kernel='gaussian', bw=0.3)\n",
    "    ss_kde = estimator.fit(ss_train).evaluate(x)\n",
    "    ds_kde = estimator.fit(ds_train).evaluate(x)\n",
    "    \n",
    "    \n",
    "    #Compute LR for the test set.\n",
    "    lr_ss_norm = []\n",
    "    lr_ds_norm = []\n",
    "    lr_ss_kde = []\n",
    "    lr_ds_kde = []\n",
    "    for score in ss_test:\n",
    "        lr_ss_norm.append(lr(score,\"gauss\"))\n",
    "        lr_ss_kde.append(lr(score,\"kde\"))\n",
    "    for score in ds_test:\n",
    "        lr_ds_norm.append(lr(score,\"gauss\"))\n",
    "        lr_ds_kde.append(lr(score,\"kde\"))\n",
    "    \n",
    "    #Compute CLLR for a set of LR values, composed of two arrays (one from matches and one from non_matches)\n",
    "    cllr_norm.append(get_cllr(lr_ss_norm, lr_ds_norm))\n",
    "    cllr_kde.append(get_cllr(lr_ss_kde, lr_ds_kde))\n",
    "    print(\"\\n fold: {} / CLLR(gauss): {:.3f} / CLLR(kde): {:.3f}\".format(i,cllr_norm[i],cllr_kde[i]))\n",
    "    \n",
    "    #get 5 smallest ss scores and 5 highest ds scores\n",
    "    #small5 = np.partition(ss_test,5)[:5]\n",
    "    #high5 = np.partition(ds_test,-5)[-5:]\n",
    "#    print(\"5 smallest ss scores:\", small5)\n",
    "#    print(\"5 highest ds scores:\", high5)\n",
    "cllr_norm_mean = np.mean(cllr_norm)\n",
    "cllr_norm_dev = np.std(cllr_norm)\n",
    "cllr_kde_mean = np.mean(cllr_kde)\n",
    "cllr_kde_dev = np.std(cllr_kde)\n",
    "print(\"\\nGaussian fit:\\nCLLR (mean): {:.3f} / CLLR (std dev): {:.3f}\".format(cllr_norm_mean, cllr_norm_dev))\n",
    "print(\"\\nKDE fit:\\nCLLR (mean): {:.3f} / CLLR (std dev): {:.3f}\".format(cllr_kde_mean, cllr_kde_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "563px",
    "left": "1230px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
